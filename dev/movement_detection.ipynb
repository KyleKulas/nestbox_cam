{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is being used to develope and test the code. It is a WIP and \n",
    "probably contains errors, bad code, bad formatting, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "VIDEO_DIR = r'C:\\Users\\kylek\\test_cam_videos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movement_times(\n",
    "        file_path, \n",
    "        movement_threshold=20_000_000, \n",
    "        frames_to_skip=10):\n",
    "    \"\"\"Function to analyze video file and return times which contain movement. \n",
    "    Uses OpenCV background subtractor to create a movement mask where white \n",
    "    pixels represent movement and black represents no movement. The pixels are \n",
    "    then summed. Higher sums indicates more movement in the frame. If the sum\n",
    "    is above the movement_threshold, movement is detected and the frame number\n",
    "    is noted. Subsequent frames are processed and when the sum drops below the\n",
    "    movement_threshold and the movement end time is noted. \n",
    "    \n",
    "    Parameters:\n",
    "    file_path:      path to the video file\n",
    "    movement_threshold:     Threshold for which the sum of all pixel in the \n",
    "                            movement mask indicated movement within the frame.\n",
    "                            Higher number results in less false positives but \n",
    "                            may not detect small movements within the frame.\n",
    "                            Default = 20,000,000\n",
    "    frames_to_skip:     Number of frames that are skipped during analysis. \n",
    "                        Default = 10\n",
    "\n",
    "    Returns:\n",
    "    movement_times:     List containing movement times in the form of \n",
    "                        [[start, finish], ...]\n",
    "\n",
    "    \"\"\"\n",
    "    # Initialize variables\n",
    "    movement_dectected = False\n",
    "    movement_times = []\n",
    "    movement_start_time = 0\n",
    "    movement_finish_time = 0\n",
    "    frame_sum = 0\n",
    "\n",
    "    # Inititalize backgroung subtractor\n",
    "    background_subtractor = cv2.createBackgroundSubtractorMOG2() \n",
    "    \n",
    "    # Start video capture\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Loop through all frames in video \n",
    "    for current_frame in trange(0, total_frame_count, frames_to_skip):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, current_frame)\n",
    "        success, frame = cap.read()\n",
    "        if success:\n",
    "            # Apply background subtractor, then threshold to get only areas with\n",
    "            # high difference, then erode to reduce noise\n",
    "            fg_mask = background_subtractor.apply(frame)\n",
    "            _, fg_mask = cv2.threshold(fg_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "            kernel = np.ones((5,5),np.uint8)\n",
    "            fg_mask = cv2.erode(fg_mask,kernel,iterations = 1)\n",
    "            # Sum all movement pixel in the frame\n",
    "            frame_sum = fg_mask.sum()\n",
    "\n",
    "            # Record start of movement time\n",
    "            if frame_sum > movement_threshold and movement_dectected == False:\n",
    "                movement_start_time = current_frame / fps\n",
    "                movement_dectected = True\n",
    "            # Record end of movement time\n",
    "            if frame_sum < movement_threshold and movement_dectected == True:\n",
    "                movement_finish_time = current_frame / fps\n",
    "                movement_times.append([movement_start_time,movement_finish_time])\n",
    "                movement_dectected = False\n",
    "\n",
    "        else:\n",
    "            # Frame capture read not successful, go to next frame\n",
    "            continue\n",
    "\n",
    "    # Record end of movement time if movement continues through the last frame\n",
    "    if frame_sum < movement_threshold and movement_dectected == True:\n",
    "        movement_finish_time = current_frame / fps\n",
    "        movement_times.append([movement_start_time,movement_finish_time])\n",
    "        movement_dectected = False\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    return movement_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_movement_times(movement_times, max_time_between_movements=5):\n",
    "    \"\"\"Function to combine movement times that are close together into single\n",
    "    movement times\"\"\"\n",
    "\n",
    "    if len(movement_times) == 0:\n",
    "        return []\n",
    "    elif len(movement_times) == 1:\n",
    "        return movement_times.copy()\n",
    "\n",
    "    cleaned_movement_times = []    \n",
    "    new_movement = movement_times[0].copy()\n",
    "    # look ahead to the next movement, if it happens less than the max time, \n",
    "    # combine movements. Otherwise start a new movement\n",
    "    for idx in range(len(movement_times)-1):\n",
    "        next_movement_start = movement_times[idx + 1][0]\n",
    "        if next_movement_start - new_movement[1] < max_time_between_movements:\n",
    "            new_movement[1] = movement_times[idx + 1][1]\n",
    "        else:\n",
    "            cleaned_movement_times.append(new_movement)\n",
    "            new_movement = movement_times[idx + 1].copy()\n",
    "\n",
    "    # since the for loop does not append the last movement, we need to check if\n",
    "    # the last movement time is a new movement of part of the previous movement\n",
    "    if movement_times[-1][1] == new_movement[1]:\n",
    "        cleaned_movement_times.append(new_movement)\n",
    "    else:\n",
    "        cleaned_movement_times.append(movement_times[-1].copy())\n",
    "    \n",
    "    return cleaned_movement_times\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_short_movements(movement_times, min_duration=2):\n",
    "    \"\"\"Remove movement times that are short duration\"\"\"\n",
    "    cleaned_movement_times = []\n",
    "    for movement in movement_times:\n",
    "        if movement[1] - movement[0] > min_duration:\n",
    "            cleaned_movement_times.append(movement)\n",
    "    \n",
    "    return cleaned_movement_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_movement_subclips(movement_times, video_file):\n",
    "    \"\"\"Split video file into seperate clips based on movement_times\"\"\"\n",
    "    highlights_dir = os.path.join(VIDEO_DIR, 'highlights')\n",
    "    # Create highlights directory if it doesn't exist\n",
    "    if os.path.exists(highlights_dir) == False:\n",
    "        os.mkdir(highlights_dir)\n",
    "    # Split video base on movement_times\n",
    "    for idx, movement in enumerate(movement_times):\n",
    "        ffmpeg_extract_subclip(\n",
    "            os.path.join(VIDEO_DIR,video_file), \n",
    "            t1=movement[0]-1, \n",
    "            t2=movement[1]+1, \n",
    "            targetname=os.path.join(highlights_dir,f\"{video_file[:-4]}_{idx}.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_video_to_checked_log(video):\n",
    "    \"\"\"Add video name to log of processed videos\"\"\"\n",
    "    with open(os.path.join(VIDEO_DIR,\"videos_checked.txt\"), \"a\") as f:\n",
    "        f.write(video + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_checked_video_list():\n",
    "    \"\"\"Get list of videos that have already been processed\"\"\"\n",
    "    try:\n",
    "        with open(os.path.join(VIDEO_DIR,\"videos_checked.txt\"), 'r') as f:\n",
    "            return [line.rstrip('\\n') for line in f]\n",
    "    except FileNotFoundError:\n",
    "        return []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/3 File: video_20230302-121001.mp4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29ed7a27f0f436f8f78cbb23830661f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "Completed in 120.5s 2 highlights found.\n",
      "Processing 2/3 File: video_20230302-122001.mp4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3048049a7d664b02bbd197ba8fd9c3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1801 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 115.5s 0 highlights found.\n",
      "Processing 3/3 File: video_20230302-123002.mp4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554674ea69a240838054c2a5844311d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 115.7s 0 highlights found.\n"
     ]
    }
   ],
   "source": [
    "videos_checked = get_checked_video_list()\n",
    "video_files = sorted([f for f in os.listdir(VIDEO_DIR) if f.endswith('.mp4')])\n",
    "new_videos = [video for video in video_files if video not in videos_checked]\n",
    "counter = 1\n",
    "total_videos_to_process = len(new_videos)\n",
    "print(f'{total_videos_to_process} new videos found.')\n",
    "for video in new_videos:\n",
    "    print(f'Processing video {counter}/{total_videos_to_process}: {video}')\n",
    "    movement_times = get_movement_times(os.path.join(VIDEO_DIR,video))\n",
    "    condensed_movement_times = combine_movement_times(movement_times)\n",
    "    cleaned_movement_times = remove_short_movements(condensed_movement_times)\n",
    "    create_movement_subclips(cleaned_movement_times,video)\n",
    "    add_video_to_checked_log(video)\n",
    "    print(f'{len(cleaned_movement_times)} highlights found.')\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "877023a8d0e9ab609a44c78c1c54caa35c22066a88df6cfc22e341f355d10fed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
